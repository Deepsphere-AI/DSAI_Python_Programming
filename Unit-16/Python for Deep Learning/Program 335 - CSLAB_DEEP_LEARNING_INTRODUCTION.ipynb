{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-16/Python%20for%20Deep%20Learning/Program%20335%20-%20CSLAB_DEEP_LEARNING_INTRODUCTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZDYuUM6pBsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ce5ade-16af-4cc8-f427-0ee08aff459e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2654 - accuracy: 0.9228\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1070 - accuracy: 0.9665\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0738 - accuracy: 0.9769\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9714\n",
            "0.08996118605136871\n",
            "0.9714000225067139\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# /*********************************************************************************************************************\n",
        "  \n",
        "#   File Name \t:   CSLAB_DEEP_LEARNING_INTRODUCTION\n",
        "#   Purpose \t:   A Program in Python for Introduction to Deep Learning\n",
        "#   Author\t:   Deepshere.ai\n",
        "#   Reviewer \t:   Jothi Periasamy\n",
        "#   Date \t:   25/10/2022 \n",
        "#   Version\t:   1.0\t\n",
        "\n",
        "# /***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program for Introduction to Deep Learning in Python\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda\n",
        "\n",
        "# deep learning library. Tensors are just multi-dimensional arrays\n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "import tensorflow as vAR_tf  \n",
        "\n",
        "# mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
        "\n",
        "vAR_CSLAB_mnist = vAR_tf.keras.datasets.mnist  \n",
        "\n",
        "# unpacks images to x_train/x_test and labels to y_train/y_test\n",
        "\n",
        "(vAR_CSLAB_x_train, vAR_CSLAB_y_train),(vAR_CSLAB_x_test, vAR_CSLAB_y_test) = vAR_CSLAB_mnist.load_data()  \n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "# scales data between 0 and 1\n",
        "\n",
        "vAR_CSLAB_x_train = vAR_tf.keras.utils.normalize(vAR_CSLAB_x_train, axis=1)  \n",
        "\n",
        "vAR_CSLAB_x_test = vAR_tf.keras.utils.normalize(vAR_CSLAB_x_test, axis=1) \n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "# a basic feed-forward model\n",
        "\n",
        "vAR_CSLAB_model = vAR_tf.keras.models.Sequential()  \n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "# takes our 28x28 and makes it 1x784\n",
        "\n",
        "vAR_CSLAB_model.add(vAR_tf.keras.layers.Flatten())  \n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "# a simple fully-connected layer, 128 units, relu activation\n",
        "\n",
        "vAR_CSLAB_model.add(vAR_tf.keras.layers.Dense(128, activation=vAR_tf.nn.relu))  \n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "# a simple fully-connected layer, 128 units, relu activation\n",
        "\n",
        "vAR_CSLAB_model.add(vAR_tf.keras.layers.Dense(128, activation=vAR_tf.nn.relu))  \n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "# our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
        "\n",
        "vAR_CSLAB_model.add(vAR_tf.keras.layers.Dense(10, activation=vAR_tf.nn.softmax))  \n",
        "\n",
        "vAR_CSLAB_model.compile(optimizer='adam',  # Good default optimizer to start with\n",
        "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
        "              metrics=['accuracy'])  # what to track\n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "vAR_CSLAB_model.fit(vAR_CSLAB_x_train, vAR_CSLAB_y_train, epochs=3)  # train the model\n",
        "\n",
        "#*********************************************************************************\n",
        "\n",
        "vAR_CSLAB_val_loss, vAR_CSLAB_val_acc = vAR_CSLAB_model.evaluate(vAR_CSLAB_x_test, vAR_CSLAB_y_test)  # evaluate the out of sample data with model\n",
        "\n",
        "print(vAR_CSLAB_val_loss)  # model's loss (error)\n",
        "\n",
        "print(vAR_CSLAB_val_acc)  # model's accuracy\n",
        "\n",
        "vAR_CSLAB_model.save('epic_num_reader.model')\n",
        "\n",
        "# /****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# /****************************************************************************************************************************\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The code is a script that uses the TensorFlow library to build, train, and evaluate a simple neural network to classify images of handwritten digits from the MNIST dataset.\n",
        "\n",
        "Here's a step-by-step explanation of what's happening:\n"
      ],
      "metadata": {
        "id": "E16nK3Uf8vRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The first line import tensorflow as vAR_tf imports the TensorFlow library as the variable vAR_tf."
      ],
      "metadata": {
        "id": "B3nC2E17boOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The next line vAR_CSLAB_mnist = vAR_tf.keras.datasets.mnist loads the MNIST dataset using the keras API, which is now part of TensorFlow. The loaded dataset is stored in the variable vAR_CSLAB_mnist."
      ],
      "metadata": {
        "id": "vbMri2ErbxFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. The line (vAR_CSLAB_x_train, vAR_CSLAB_y_train),(vAR_CSLAB_x_test, vAR_CSLAB_y_test) = vAR_CSLAB_mnist.load_data() unpack the images and labels from the MNIST dataset into four separate variables: vAR_CSLAB_x_train, vAR_CSLAB_y_train, vAR_CSLAB_x_test, and vAR_CSLAB_y_test."
      ],
      "metadata": {
        "id": "o7r2o_EDb_2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. The next two lines vAR_CSLAB_x_train = vAR_tf.keras.utils.normalize(vAR_CSLAB_x_train, axis=1) and vAR_CSLAB_x_test = vAR_tf.keras.utils.normalize(vAR_CSLAB_x_test, axis=1) scale the pixel values of the images between 0 and 1, which is a common preprocessing step."
      ],
      "metadata": {
        "id": "7W68ujW8cAHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. The next block of code creates a simple feedforward neural network using the Sequential API from vAR_tf.keras.models"
      ],
      "metadata": {
        "id": "IKJw3ZI7cASp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. The line vAR_CSLAB_model.add(vAR_tf.keras.layers.Flatten()) flattens the 28x28 images into a 1x784 vector, so that they can be input into the fully connected layers of the network."
      ],
      "metadata": {
        "id": "rqE8LL-bcAdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. The next two lines vAR_CSLAB_model.add(vAR_tf.keras.layers.Dense(128, activation=vAR_tf.nn.relu)) add two fully connected (dense) layers to the network, each with 128 units and a rectified linear unit (ReLU) activation function."
      ],
      "metadata": {
        "id": "2JpEY6IqcAnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. The final line vAR_CSLAB_model.add(vAR_tf.keras.layers.Dense(10, activation=vAR_tf.nn.softmax)) adds an output layer with 10 units and a softmax activation function. The softmax activation is used to produce a probability distribution over the 10 possible classes."
      ],
      "metadata": {
        "id": "2KMq6SYvcAus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. The next line vAR_CSLAB_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) compiles the model with an Adam optimizer, a loss function of sparse categorical cross-entropy, and accuracy as a metric to track."
      ],
      "metadata": {
        "id": "C6GnuNjucA2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. The line vAR_CSLAB_model.fit(vAR_CSLAB_x_train, vAR_CSLAB_y_train, epochs=3) trains the model for 3 epochs"
      ],
      "metadata": {
        "id": "as2MtXudcA83"
      }
    }
  ]
}