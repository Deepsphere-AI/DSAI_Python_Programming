{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-16/Python%20for%20Deep%20Learning/Program%20354-%20CSLAB_DEEP_LEARNING_KERAS_CIFAR10_CNN_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWsL5KFe8p7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "712fc90d-c3a9-46c9-f87e-5e8054aca56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Using real-time data augmentation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-11ac39477567>:116: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  vAR_CSLAB_model.fit_generator(vAR_CSLAB_datagen.flow(vAR_CSLAB_x_train, vAR_CSLAB_y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 266s 170ms/step - loss: 1.9181 - accuracy: 0.2929 - val_loss: 1.6380 - val_accuracy: 0.4158\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "313/313 [==============================] - 11s 36ms/step - loss: 1.6380 - accuracy: 0.4158\n",
            "Test loss: 1.6379849910736084\n",
            "Test accuracy: 0.415800005197525\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_DEEP_LEARNING_KERAS_CIFAR10_CNN_CLASSIFICATION\n",
        "  # Purpose \t:   A Program in Python for Cifar10 Image Classification using Keras Library in Deep Learning\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   28/10/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program in Python for Cifar10 Image Classification using Keras Library in Deep Learning\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "#from keras import optimizers\n",
        "from tensorflow.keras import optimizers\n",
        "#optimizer=keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "import os\n",
        "\n",
        "vAR_CSLAB_batch_size = 32\n",
        "vAR_CSLAB_num_classes = 10\n",
        "vAR_CSLAB_epochs = 1\n",
        "vAR_CSLAB_data_augmentation = True\n",
        "vAR_CSLAB_num_predictions = 20\n",
        "vAR_CSLAB_save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "vAR_CSLAB_model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(vAR_CSLAB_x_train, vAR_CSLAB_y_train), (vAR_CSLAB_x_test, vAR_CSLAB_y_test) = cifar10.load_data()\n",
        "print('x_train shape:', vAR_CSLAB_x_train.shape)\n",
        "print(vAR_CSLAB_x_train.shape[0], 'train samples')\n",
        "print(vAR_CSLAB_x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "vAR_CSLAB_y_train = keras.utils.to_categorical(vAR_CSLAB_y_train, vAR_CSLAB_num_classes)\n",
        "vAR_CSLAB_y_test = keras.utils.to_categorical(vAR_CSLAB_y_test, vAR_CSLAB_num_classes)\n",
        "\n",
        "vAR_CSLAB_model = Sequential()\n",
        "vAR_CSLAB_model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=vAR_CSLAB_x_train.shape[1:]))\n",
        "vAR_CSLAB_model.add(Activation('relu'))\n",
        "vAR_CSLAB_model.add(Conv2D(32, (3, 3)))\n",
        "vAR_CSLAB_model.add(Activation('relu'))\n",
        "vAR_CSLAB_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "vAR_CSLAB_model.add(Dropout(0.25))\n",
        "\n",
        "vAR_CSLAB_model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "vAR_CSLAB_model.add(Activation('relu'))\n",
        "vAR_CSLAB_model.add(Conv2D(64, (3, 3)))\n",
        "vAR_CSLAB_model.add(Activation('relu'))\n",
        "vAR_CSLAB_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "vAR_CSLAB_model.add(Dropout(0.25))\n",
        "\n",
        "vAR_CSLAB_model.add(Flatten())\n",
        "vAR_CSLAB_model.add(Dense(512))\n",
        "vAR_CSLAB_model.add(Activation('relu'))\n",
        "vAR_CSLAB_model.add(Dropout(0.5))\n",
        "vAR_CSLAB_model.add(Dense(vAR_CSLAB_num_classes))\n",
        "vAR_CSLAB_model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "vAR_CSLAB_opt = optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "vAR_CSLAB_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=vAR_CSLAB_opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "vAR_CSLAB_x_train = vAR_CSLAB_x_train.astype('float32')\n",
        "vAR_CSLAB_x_test = vAR_CSLAB_x_test.astype('float32')\n",
        "vAR_CSLAB_x_train /= 255\n",
        "vAR_CSLAB_x_test /= 255\n",
        "\n",
        "if not vAR_CSLAB_data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    vAR_CSLAB_model.fit(vAR_CSLAB_x_train, vAR_CSLAB_y_train,\n",
        "              batch_size=vAR_CSLAB_batch_size,\n",
        "              epochs=vAR_CSLAB_epochs,\n",
        "              validation_data=(vAR_CSLAB_x_test, vAR_CSLAB_y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    vAR_CSLAB_datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,  \n",
        "        zca_epsilon=1e-06,  \n",
        "        rotation_range=0,  \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "    vAR_CSLAB_datagen.fit(vAR_CSLAB_x_train)\n",
        "\n",
        "    vAR_CSLAB_model.fit_generator(vAR_CSLAB_datagen.flow(vAR_CSLAB_x_train, vAR_CSLAB_y_train,\n",
        "                                     batch_size=vAR_CSLAB_batch_size),\n",
        "                        epochs=vAR_CSLAB_epochs,\n",
        "                        validation_data=(vAR_CSLAB_x_test, vAR_CSLAB_y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(vAR_CSLAB_save_dir):\n",
        "    os.makedirs(vAR_CSLAB_save_dir)\n",
        "vAR_CSLAB_model_path = os.path.join(vAR_CSLAB_save_dir, vAR_CSLAB_model_name)\n",
        "vAR_CSLAB_model.save(vAR_CSLAB_model_path)\n",
        "print('Saved trained model at %s ' % vAR_CSLAB_model_path)\n",
        "\n",
        "# Score trained model.\n",
        "vAR_CSLAB_scores = vAR_CSLAB_model.evaluate(vAR_CSLAB_x_test, vAR_CSLAB_y_test, verbose=1)\n",
        "print('Test loss:', vAR_CSLAB_scores[0])\n",
        "print('Test accuracy:', vAR_CSLAB_scores[1])\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The code is a script for training a convolutional neural network on the CIFAR-10 dataset using the Keras library. CIFAR-10 is a dataset of 60,000 32x32 color training images and 10,000 test images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images."
      ],
      "metadata": {
        "id": "-z8XH9EsMwMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, the script imports several libraries, including the print_function from the __future__ module, which is used to specify the behavior of the print statement in Python 3.x, keras for building the ConvNet, cifar10 for loading the CIFAR-10 dataset, ImageDataGenerator for augmenting the training data, Sequential for building the ConvNet layer-by-layer, and several layers from Keras, including Dense, Dropout, Activation, Flatten, Conv2D, and MaxPooling2D.\n",
        "\n",
        "Next, several variables are defined, including the batch size, number of classes, number of epochs, whether to perform data augmentation, number of predictions, and the directory to save the model."
      ],
      "metadata": {
        "id": "160gD-NWMwqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, several variables are defined, including the batch size, number of classes, number of epochs, whether to perform data augmentation, number of predictions, and the directory to save the model.\n",
        "\n",
        "The script then loads the CIFAR-10 dataset into the memory and prints the shape of the training and test data. The class vectors of the training and test data are then converted to binary class matrices, which are used to represent the output targets."
      ],
      "metadata": {
        "id": "EDDrBq-JMww4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A ConvNet is then created by defining a Sequential model and adding the layers one by one. The first layer is a 2D convolutional layer with 32 filters, each with a size of 3x3. The second layer is an activation layer using the rectified linear unit (ReLU) activation function. The third layer is another 2D convolutional layer with 32 filters, followed by another ReLU activation layer. The fourth layer is a max pooling layer with a pool size of 2x2. The fifth layer is a dropout layer with a rate of 0.25, which helps to prevent overfitting. This process is repeated for several more convolutional and max pooling layers, with each additional layer increasing the size of the filters and reducing the spatial dimensions of the feature maps.\n",
        "\n",
        "Finally, a dense layer with 512 neurons is added, followed by a ReLU activation layer, a dropout layer with a rate of 0.5, and a dense output layer with 10 neurons, one for each class."
      ],
      "metadata": {
        "id": "SWB9FqGXMw_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is then compiled using the categorical cross-entropy loss function, which is used for multi-class classification problems, and the RMSprop optimizer, which is an optimization algorithm that makes use of the moving average of the squares of the gradient to scale the learning rate.\n",
        "\n",
        "The training and test data are then normalized by dividing each pixel value by 255, which scales the data to the range [0, 1].\n",
        "\n",
        "If data augmentation is not enabled, the model is trained for the specified number of epochs using the fit method of the Sequential model. If data augmentation is enabled, the script uses the ImageDataGenerator class from the keras.preprocessing.image module to generate new training data by applying random transformations to the original images, such as rotation, scaling, and flipping.\n",
        "\n",
        "Finally, the model is saved to the specified directory with the specified name."
      ],
      "metadata": {
        "id": "l3k0YIMwMxL9"
      }
    }
  ]
}