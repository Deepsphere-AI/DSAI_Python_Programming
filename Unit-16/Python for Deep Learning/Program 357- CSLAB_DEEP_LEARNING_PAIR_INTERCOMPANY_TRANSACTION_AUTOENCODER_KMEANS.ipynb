{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyxTHoP36tZXj3BR8XCiWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-16/Python%20for%20Deep%20Learning/Program%20357-%20CSLAB_DEEP_LEARNING_PAIR_INTERCOMPANY_TRANSACTION_AUTOENCODER_KMEANS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmG0MTRP_H0O"
      },
      "outputs": [],
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_DEEP_LEARNING_PAIR_INTERCOMPANY_TRANSACTION_AUTOENCODER_KMEANS\n",
        "  # Purpose \t:   A Program in Python for Pair Intercompany Transaction Using Autoencoder & Kmeans Clustering in Deep Learning\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   28/10/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program in Python for Pair Intercompany Transaction Using Autoencoder & Kmeans Clustering in Deep Learning\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda\n",
        "\n",
        "# coding=utf-8\n",
        "\n",
        "# Step 0 - Read Data from .INI File for Hardcoded Values\n",
        "\n",
        "import sys\n",
        "#print('Arguments:', len(sys.argv))\n",
        "#vAR_Fetched_Data_INI_File_Path = sys.argv[1]\n",
        "#print(vAR_Fetched_Data_INI_File_Path)\n",
        "\n",
        "import configparser\n",
        "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
        "\n",
        "import os\n",
        "\n",
        "vAR_INI_File_Path = os.environ.get('PYTHON_TUTORIAL')\n",
        "\n",
        "import pandas as vAR_pd\n",
        "\n",
        "import configparser\n",
        "\n",
        "import pandas as vAR_pd\n",
        "\n",
        "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
        "\n",
        "vAR_Config.read(vAR_INI_File_Path)\n",
        "\n",
        "vAR_CSLAB_INI_File = vAR_Config['Data File Path']['vAR_CSLAB_PROGRAM_357_INI_FILE']  \n",
        "\n",
        "vAR_Config.read(vAR_CSLAB_INI_File)\n",
        "\n",
        "vAR_Data = vAR_Config.sections()\n",
        "\n",
        "vAR_Config.sections()\n",
        "\n",
        "vAR_Fetched_Data_Source = vAR_Config['Data Source']['DATA_SOURCE1']\n",
        "#print(vAR_Fetched_Data_Source)\n",
        "\n",
        "vAR_Fetched_Data_Source_Connection_String = vAR_Config['Data Source Connection String']['SAP_CONNECTION_STRING']\n",
        "#print(vAR_Fetched_Data_Source_Connection_String)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Input_Data = vAR_Config['Data Source Path']['INPUT_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Input_Data)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Train_Data = vAR_Config['Data Source Path']['TRAIN_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Train_Data)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Test_Data = vAR_Config['Data Source Path']['Test_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features1 = vAR_Config['Train Features - Problem 1']['FEATURE1']\n",
        "#print(vAR_Fetched_Data_Train_Features1)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features2 = vAR_Config['Train Features - Problem 1']['FEATURE2']\n",
        "#print(vAR_Fetched_Data_Train_Features2)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features3 = vAR_Config['Train Features - Problem 1']['FEATURE3']\n",
        "#print(vAR_Fetched_Data_Train_Features3)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features4 = vAR_Config['Train Features - Problem 1']['FEATURE4']\n",
        "#print(vAR_Fetched_Data_Train_Features4)\n",
        "\n",
        "vAR_Fetched_Data_Train_All_Features = vAR_Config['Train Features - Problem 1']['ALL_FEATURES_TRAIN']\n",
        "#print(vAR_Fetched_Data_Train_All_Features)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features1 = vAR_Config['Train Features - Problem 1']['FEATURE1']\n",
        "#print(vAR_Fetched_Data_Test_Features1)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features2 = vAR_Config['Train Features - Problem 1']['FEATURE2']\n",
        "#print(vAR_Fetched_Data_Test_Features2)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features3 = vAR_Config['Train Features - Problem 1']['FEATURE3']\n",
        "#print(vAR_Fetched_Data_Test_Features3)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features4 = vAR_Config['Train Features - Problem 1']['FEATURE4']\n",
        "#print(vAR_Fetched_Data_Test_Features4)\n",
        "\n",
        "vAR_Fetched_Data_Test_All_Features = vAR_Config['Test Features - Problem 1']['ALL_FEATURES_TEST']\n",
        "#print(vAR_Fetched_Data_Test_All_Features)\n",
        "\n",
        "vAR_Fetched_Data_Model_Path = vAR_Config['Model Ouput Path']['MODEL_OUTPUT_PATH']\n",
        "#print(vAR_Fetched_Data_Model_Path)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_1 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_2 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_3 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_1 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_2 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_3 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_1 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_2 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_3 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_1 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_2 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_3 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_1 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_2 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_3 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_1 = vAR_Config['Model Fitting']['OvER_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_2 = vAR_Config['Model Fitting']['OvER_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_3 = vAR_Config['Model Fitting']['OVER_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_1 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_2 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_3 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Before_Hyperparameter_Tuning_Image = vAR_Config['Model_Validation_Tuning']['BEFORE_HYPERPARAMETER_TUNING_IMAGE']\n",
        "#print(vAR_Fetched_Data_Before_Hyperparameter_Tuning_Image)\n",
        "\n",
        "vAR_Fetched_Data_After_Hyperparameter_Tuning_Image = vAR_Config['Model_Validation_Tuning']['AFTER_HYPERPARAMETER_TUNING_IMAGE']\n",
        "#print(vAR_Fetched_Data_After_Hyperparameter_Tuning_Image)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Best_Fit_Test = vAR_Config['Model Fitting']['BEST_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Best_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Under_Fit_Test = vAR_Config['Model Fitting']['UNDER_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Under_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Over_Fit_Test = vAR_Config['Model Fitting']['OVER_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Over_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Required = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_REQUIRED']\n",
        "#print(Fetched_Data_Cross_Validation_Required)\n",
        "\n",
        "vAR_Fetched_Data_Hyperparameter_Tuning_Required = vAR_Config['Model_Validation_Tuning']['HYPERPARAMETERS_TUNING_REQUIRED']\n",
        "#print(Fetched_Data_Hyperparameter_Tuning_Required)\n",
        "\n",
        "# Step 1 - Import the Required Libraries\n",
        "\n",
        "#Our Model Implementation needs the Following Libraries:\n",
        "\n",
        "#Sklearn: Sklearn is the Machine Learning Library which is used for numerical & scientific computations.\n",
        "\n",
        "#Pandas: Pandas is a library used for data manipulation and analysis. \n",
        "\n",
        "#In Our Implementation. we are using it for Importing the Data file & Creating Dataframes (Stores the Data).\n",
        "\n",
        "import pandas as vAR_pd\n",
        "from sklearn.cluster import KMeans\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "#Step 2 - Import Clustering Data\n",
        "\n",
        "#Next step after importing all libraries is getting the Training data imported. \n",
        "\n",
        "#We are importing the Clustering data stored in our local system with the use of Pandas library.\n",
        "\n",
        "vAR_df = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Train_Data)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 3 � Convert Categorical Data into Numerical Values using Label Encoder \n",
        "\n",
        "# Next Step of the Implementation is Convertion of Categorical Data into Numerical Values & Feature Selection for Clustering.\n",
        "\n",
        "vAR_le = LabelEncoder()\n",
        "vAR_Transaction_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,7])\n",
        "vAR_Transaction_Type_Conversion_df = vAR_pd.DataFrame(vAR_Transaction_Type_Conversion,columns={'Transaction_Type_Converted'})\n",
        "vAR_Data_Category_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,9])\n",
        "vAR_Data_Category_Conversion_df = vAR_pd.DataFrame(vAR_Data_Category_Conversion,columns={'Data_Category_Converted'})\n",
        "vAR_Doc_Date_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,3])\n",
        "vAR_Doc_Date_Conversion_df = vAR_pd.DataFrame(vAR_Doc_Date_Conversion,columns={'Doc_Date_Converted'})\n",
        "\n",
        "# Attached the Converted Numerical Data to the main dataframe\n",
        "\n",
        "vAR_df1 = vAR_df.merge(vAR_Transaction_Type_Conversion_df,left_index=True, right_index=True)\n",
        "vAR_df2 = vAR_df1.merge(vAR_Data_Category_Conversion_df,left_index=True, right_index=True)\n",
        "vAR_df3 = vAR_df2.merge(vAR_Doc_Date_Conversion_df,left_index=True, right_index=True)\n",
        "vAR_df4 = vAR_pd.read_excel(vAR_Fetched_Data_Train_All_Features)\n",
        "vAR_df4 = vAR_df4.values\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 4 � Clustering the Data\n",
        "\n",
        "# Clustering the data meaning Making the model to group/cluster, understand & recognize the Pattern in the data..\n",
        "\n",
        "vAR_df4 = vAR_df4.reshape(len(vAR_df4),np.prod(vAR_df4.shape[1:]))\n",
        "#vAR_df4 = vAR_df4.reshape((vAR_df4.shape[0],vAR_df4.shape[1],1))\n",
        "\n",
        "encoding_dim = 2 \n",
        "input_dim = Input(shape=(2,))\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_dim)\n",
        "decoded = Dense(2, activation='sigmoid')(encoded)\n",
        "autoencoder = Model(input_dim, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='categorical_crossentropy')\n",
        "\n",
        "autoencoder.fit(vAR_df4,vAR_df4)\n",
        "Pred = autoencoder.predict(vAR_df4)\n",
        "Pred.astype(int)\n",
        "vAR_df4 = vAR_pd.read_excel(vAR_Fetched_Data_Train_All_Features)\n",
        "\n",
        "vAR_model = KMeans(n_clusters=12,random_state=0)\n",
        "vAR_model.fit(vAR_df4)\n",
        "vAR_Class = vAR_model.labels_\n",
        "vAR_Class_df = vAR_pd.DataFrame(vAR_Class,columns={'New_Group'})\n",
        "vAR_Class_df\n",
        "vAR_df4_Class_Merge = vAR_df4.merge(vAR_Class_df,left_index=True, right_index=True) \n",
        "vAR_df4_Class_Merge\n",
        "vAR_df5 = vAR_df4_Class_Merge.iloc[:,2]\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 5 � Review Learning Algorithm\n",
        "\n",
        "# We Review the Algorithm as to see how it has learned from the Features we Provided\n",
        "\n",
        "vAR_model.predict(vAR_df4)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 6 - Import Test Data\n",
        "\n",
        "# Importing the Test Data is to check how the data used on the Model Performs\n",
        "\n",
        "vAR_df6 = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "#vAR_Data_Category_Conversion_test = vAR_le.fit_transform(vAR_df5.iloc[:,9])\n",
        "#vAR_Data_Category_Conversion_test_df = vAR_pd.DataFrame(vAR_Data_Category_Conversion_test,columns={'Data_Category_Converted_test'})\n",
        "vAR_df7 = vAR_pd.read_excel(vAR_Fetched_Data_Test_All_Features)\n",
        "\n",
        "vAR_Features_test = vAR_df7\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 7 � Running Model on Test Data\n",
        "\n",
        "# Running the Model on Test Data is to use the imported test data to Prodict our Outcome\n",
        "\n",
        "vAR_Labels_Pred = vAR_model.predict(vAR_Features_test)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 8 � Review Model Outcome\n",
        "\n",
        "# We check the Output of Model i.e the Prediction it has made on the test data\n",
        "\n",
        "vAR_Labels_Pred = vAR_pd.DataFrame(vAR_Labels_Pred,columns={'Predicted_Inter_Transaction_Pair'})\n",
        "#vAR_Features_test = vAR_Features_test.sort()\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 9 - Write Model Outcome to File\n",
        "\n",
        "# Write the Model Output to an excel file for analysis.\n",
        "\n",
        "vAR_df8 = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "vAR_df9 = vAR_df8.merge(vAR_Labels_Pred,left_index=True, right_index=True)\n",
        "vAR_df10 = vAR_df9.to_excel(vAR_Fetched_Data_Model_Path)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 10 - To open and view the file outcome\n",
        "\n",
        "# Open the Written File &amp; Check the Outcome as Shown. Execute to View the data\n",
        "\n",
        "vAR_df11 = vAR_pd.read_excel(vAR_Fetched_Data_Model_Path)\n",
        "vAR_df11\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ]
    }
  ]
}