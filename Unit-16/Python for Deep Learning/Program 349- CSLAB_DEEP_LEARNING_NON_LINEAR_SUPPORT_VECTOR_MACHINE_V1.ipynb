{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPN8dM14sKZINkylVzeVwN8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-16/Python%20for%20Deep%20Learning/Program%20349-%20CSLAB_DEEP_LEARNING_NON_LINEAR_SUPPORT_VECTOR_MACHINE_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJtA9TABuSTm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_DEEP_LEARNING_NON_LINEAR_SUPPORT_VECTOR_MACHINE_V1\n",
        "  # Purpose \t:   A Program in Python for Non Linear Support Vector Machine - Deep Learning\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   28/10/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program for Non  Linear Support Vector Machine - Deep Learning in Python\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda, Tensorflow, Tensorboard\n",
        "\n",
        "import matplotlib.pyplot as vAR_plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as vAR_np\n",
        "import tensorflow as vAR_tf\n",
        "from sklearn import datasets\n",
        "\n",
        "vAR_sess = vAR_tf.Session()\n",
        "\n",
        "vAR_CSLAB_iris = datasets.load_iris()\n",
        "vAR_CSLAB_x_vals = vAR_np.array([[x[0], x[3]] for x in vAR_CSLAB_iris.data])\n",
        "vAR_CSLAB_y_vals = vAR_np.array([1 if y==0 else -1 for y in vAR_CSLAB_iris.target])\n",
        "\n",
        "vAR_CSLAB_train_indices = vAR_np.random.choice(len(vAR_CSLAB_x_vals), round(len(vAR_CSLAB_x_vals)*0.8), replace=False)\n",
        "\n",
        "vAR_CSLAB_test_indices = vAR_np.array(list(set(range(len(vAR_CSLAB_x_vals))) - set(vAR_CSLAB_train_indices)))\n",
        "vAR_CSLAB_x_vals_train = vAR_CSLAB_x_vals[vAR_CSLAB_train_indices]\n",
        "vAR_CSLAB_x_vals_test = vAR_CSLAB_x_vals[vAR_CSLAB_test_indices]\n",
        "vAR_CSLAB_y_vals_train = vAR_CSLAB_y_vals[vAR_CSLAB_train_indices]\n",
        "vAR_CSLAB_y_vals_test = vAR_CSLAB_y_vals[vAR_CSLAB_test_indices]\n",
        "\n",
        "vAR_CSLAB_batch_size = 101\n",
        "vAR_CSLAB_x_data = vAR_tf.placeholder(shape=[None, 2], dtype=vAR_tf.float32)\n",
        "vAR_CSLAB_y_target = vAR_tf.placeholder(shape=[None, 1], dtype=vAR_tf.float32)\n",
        "vAR_CSLAB_prediction_grid = vAR_tf.placeholder(shape=[None, 2], dtype=vAR_tf.float32)\n",
        "vAR_CSLAB_b = vAR_tf.Variable(vAR_tf.random_normal(shape=[1,vAR_CSLAB_batch_size]))\n",
        "\n",
        "#Gaussian kernel\n",
        "vAR_CSLAB_gamma = vAR_tf.constant(-50.0)\n",
        "vAR_CSLAB_dist = vAR_tf.reduce_sum(vAR_tf.square(vAR_CSLAB_x_data), 1)\n",
        "vAR_CSLAB_dist = vAR_tf.reshape(vAR_CSLAB_dist, [-1,1])\n",
        "vAR_CSLAB_sq_dists = vAR_tf.add(vAR_tf.subtract(vAR_CSLAB_dist, vAR_tf.multiply(2., vAR_tf.matmul(vAR_CSLAB_x_data, vAR_tf.transpose(vAR_CSLAB_x_data)))), vAR_tf.transpose(vAR_CSLAB_dist))\n",
        "vAR_CSLAB_my_kernel = vAR_tf.exp(vAR_tf.multiply(vAR_CSLAB_gamma, vAR_tf.abs(vAR_CSLAB_sq_dists)))\n",
        "\n",
        "vAR_CSLAB_model_output = vAR_tf.matmul(vAR_CSLAB_b, vAR_CSLAB_my_kernel)\n",
        "\n",
        "vAR_CSLAB_first_term = vAR_tf.reduce_sum(vAR_CSLAB_b)\n",
        "vAR_CSLAB_b_vec_cross = vAR_tf.matmul(vAR_tf.transpose(vAR_CSLAB_b), vAR_CSLAB_b)\n",
        "vAR_CSLAB_y_target_cross = vAR_tf.matmul(vAR_CSLAB_y_target, vAR_tf.transpose(vAR_CSLAB_y_target))\n",
        "vAR_CSLAB_second_term = vAR_tf.reduce_sum(vAR_tf.multiply(vAR_CSLAB_my_kernel, vAR_tf.multiply(vAR_CSLAB_b_vec_cross, vAR_CSLAB_y_target_cross)))\n",
        "vAR_CSLAB_loss = vAR_tf.negative(vAR_tf.subtract(vAR_CSLAB_first_term, vAR_CSLAB_second_term))\n",
        "\n",
        "vAR_CSLAB_rA = vAR_tf.reshape(vAR_tf.reduce_sum(vAR_tf.square(vAR_CSLAB_x_data), 1),[-1,1])\n",
        "vAR_CSLAB_rB = vAR_tf.reshape(vAR_tf.reduce_sum(vAR_tf.square(vAR_CSLAB_prediction_grid), 1),[-1,1])\n",
        "vAR_CSLAB_pred_sq_dist = vAR_tf.add(vAR_tf.subtract(vAR_CSLAB_rA, vAR_tf.multiply(2., vAR_tf.matmul(vAR_CSLAB_x_data, vAR_tf.transpose(vAR_CSLAB_prediction_grid)))), vAR_tf.transpose(vAR_CSLAB_rB))\n",
        "vAR_CSLAB_pred_kernel = vAR_tf.exp(vAR_tf.multiply(vAR_CSLAB_gamma, vAR_tf.abs(vAR_CSLAB_pred_sq_dist)))\n",
        "\n",
        "vAR_CSLAB_prediction_output = vAR_tf.matmul(vAR_tf.multiply(vAR_tf.transpose(vAR_CSLAB_y_target),vAR_CSLAB_b), vAR_CSLAB_pred_kernel)\n",
        "vAR_CSLAB_prediction = vAR_tf.sign(vAR_CSLAB_prediction_output-vAR_tf.reduce_mean(vAR_CSLAB_prediction_output))\n",
        "vAR_CSLAB_accuracy = vAR_tf.reduce_mean(vAR_tf.cast(vAR_tf.equal(vAR_tf.squeeze(vAR_CSLAB_prediction), vAR_tf.squeeze(vAR_CSLAB_y_target)), vAR_tf.float32))\n",
        "\n",
        "vAR_CSLAB_my_opt = vAR_tf.train.GradientDescentOptimizer(0.001)\n",
        "vAR_CSLAB_train_step = vAR_CSLAB_my_opt.minimize(vAR_CSLAB_loss)\n",
        "vAR_CSLAB_init = vAR_tf.global_variables_initializer()\n",
        "vAR_sess.run(vAR_CSLAB_init)\n",
        "\n",
        "vAR_CSLAB_loss_vec = []\n",
        "vAR_CSLAB_batch_accuracy = []\n",
        "for i in range(500):\n",
        "    vAR_CSLAB_rand_index = vAR_np.random.choice(len(vAR_CSLAB_x_vals_train), size=vAR_CSLAB_batch_size)\n",
        "    vAR_CSLAB_rand_x = vAR_CSLAB_x_vals_train[vAR_CSLAB_rand_index]\n",
        "    vAR_CSLAB_rand_y = vAR_np.transpose([vAR_CSLAB_y_vals_train[vAR_CSLAB_rand_index]])\n",
        "    vAR_sess.run(vAR_CSLAB_train_step, feed_dict={vAR_CSLAB_x_data: vAR_CSLAB_rand_x, vAR_CSLAB_y_target: vAR_CSLAB_rand_y})\n",
        "    \n",
        "    vAR_sess.run(vAR_CSLAB_train_step, feed_dict={vAR_CSLAB_x_data: vAR_CSLAB_rand_x, vAR_CSLAB_y_target: vAR_CSLAB_rand_y})\n",
        "    vAR_CSLAB_temp_loss = vAR_sess.run(vAR_CSLAB_loss, feed_dict={vAR_CSLAB_x_data: vAR_CSLAB_rand_x, vAR_CSLAB_y_target: vAR_CSLAB_rand_y})\n",
        "    vAR_CSLAB_loss_vec.append(vAR_CSLAB_temp_loss)\n",
        "    \n",
        "    vAR_CSLAB_acc_temp = vAR_sess.run(vAR_CSLAB_accuracy, feed_dict={vAR_CSLAB_x_data: vAR_CSLAB_rand_x,vAR_CSLAB_y_target: vAR_CSLAB_rand_y,vAR_CSLAB_prediction_grid:vAR_CSLAB_rand_x})\n",
        "    vAR_CSLAB_batch_accuracy.append(vAR_CSLAB_acc_temp)\n",
        "    \n",
        "    if (i+1)%100==0:\n",
        "        print('Step #' + str(i+1))\n",
        "        print('Loss = ' + str(vAR_CSLAB_temp_loss))\n",
        "        \n",
        "vAR_CSLAB_x_min, vAR_CSLAB_x_max = vAR_CSLAB_x_vals[:, 0].min() - 1, vAR_CSLAB_x_vals[:, 0].max() + 1\n",
        "vAR_CSLAB_y_min, vAR_CSLAB_y_max = vAR_CSLAB_x_vals[:, 1].min() - 1, vAR_CSLAB_x_vals[:, 1].max() + 1\n",
        "vAR_CSLAB_xx, vAR_CSLAB_yy = vAR_np.meshgrid(vAR_np.arange(vAR_CSLAB_x_min, vAR_CSLAB_x_max, 0.02),vAR_np.arange(vAR_CSLAB_y_min, vAR_CSLAB_y_max, 0.02))\n",
        "vAR_CSLAB_grid_points = vAR_np.c_[vAR_CSLAB_xx.ravel(), vAR_CSLAB_yy.ravel()]\n",
        "[vAR_CSLAB_grid_predictions] = vAR_sess.run(vAR_CSLAB_prediction, feed_dict={vAR_CSLAB_x_data: vAR_CSLAB_rand_x, vAR_CSLAB_y_target: vAR_CSLAB_rand_y,vAR_CSLAB_prediction_grid: vAR_CSLAB_grid_points})\n",
        "vAR_CSLAB_grid_predictions = vAR_CSLAB_grid_predictions.reshape(vAR_CSLAB_xx.shape)\n",
        "\n",
        "(vAR_CSLAB_x_vals, vAR_CSLAB_y_vals) = datasets.make_circles(n_samples=1500, factor=.5, noise=.1)\n",
        "\n",
        "vAR_CSLAB_y_vals = vAR_np.array([1 if y==1 else -1 for y in vAR_CSLAB_y_vals])\n",
        "\n",
        "vAR_CSLAB_class1_x = [x[0] for i,x in enumerate(vAR_CSLAB_x_vals) if vAR_CSLAB_y_vals[i]==1]\n",
        "vAR_CSLAB_class1_y = [x[1] for i,x in enumerate(vAR_CSLAB_x_vals) if vAR_CSLAB_y_vals[i]==1]\n",
        "vAR_CSLAB_class2_x = [x[0] for i,x in enumerate(vAR_CSLAB_x_vals) if vAR_CSLAB_y_vals[i]==-1]\n",
        "vAR_CSLAB_class2_y = [x[1] for i,x in enumerate(vAR_CSLAB_x_vals) if vAR_CSLAB_y_vals[i]==-1]\n",
        "\n",
        "vAR_plt.contourf(vAR_CSLAB_xx, vAR_CSLAB_yy, vAR_CSLAB_grid_predictions, cmap=vAR_plt.cm.Paired, alpha=0.8)\n",
        "vAR_plt.plot(vAR_CSLAB_class1_x, vAR_CSLAB_class1_y, 'ro', label='Class 1')\n",
        "vAR_plt.plot(vAR_CSLAB_class2_x, vAR_CSLAB_class1_y, 'kx', label='Class -1')\n",
        "vAR_plt.legend(loc='lower right')\n",
        "vAR_plt.ylim([-1.5, 1.5])\n",
        "vAR_plt.xlim([-1.5, 1.5])\n",
        "vAR_plt.show()\n",
        "\n",
        "vAR_plt.plot(vAR_CSLAB_batch_accuracy, 'k-', label='Accuracy')\n",
        "vAR_plt.title('Batch Accuracy')\n",
        "vAR_plt.xlabel('Generation')\n",
        "vAR_plt.ylabel('Accuracy')\n",
        "vAR_plt.legend(loc='lower right')\n",
        "vAR_plt.show()\n",
        "\n",
        "vAR_plt.plot(vAR_CSLAB_loss_vec, 'k-')\n",
        "vAR_plt.title('Loss per Generation')\n",
        "vAR_plt.xlabel('Generation')\n",
        "vAR_plt.ylabel('Loss')\n",
        "vAR_plt.show()\n",
        "\n",
        "    \n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ]
    }
  ]
}