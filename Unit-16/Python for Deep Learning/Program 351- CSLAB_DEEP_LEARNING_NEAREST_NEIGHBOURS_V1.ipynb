{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-16/Python%20for%20Deep%20Learning/Program%20351-%20CSLAB_DEEP_LEARNING_NEAREST_NEIGHBOURS_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcmxzssa66sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c0f678-631e-4d96-c517-a89d4a347e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6819 - accuracy: 0.8329\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.9024\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3208 - accuracy: 0.9112\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.9166\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9200\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.2807 - accuracy: 0.9218\n",
            "Test accuracy: 0.9218000173568726\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_DEEP_LEARNING_NEAREST_NEIGHBOURS_V1\n",
        "  # Purpose \t:   A Program in Python for Nearest Neighbours - Deep Learning\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   28/10/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program for Nearest Neighbours - Deep Learning in Python\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda, Tensorflow, Tensorboard\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST data\n",
        "(vAR_CLAB_X_train, vAR_CLAB_y_train), (vAR_CLAB_X_test, vAR_CLAB_y_test) = mnist.load_data()\n",
        "\n",
        "# Flatten the images into a 1D array\n",
        "vAR_CLAB_X_train = vAR_CLAB_X_train.reshape(60000, 784)\n",
        "vAR_CLAB_X_test = vAR_CLAB_X_test.reshape(10000, 784)\n",
        "\n",
        "# Convert data type to float32\n",
        "vAR_CLAB_X_train = vAR_CLAB_X_train.astype('float32')\n",
        "vAR_CLAB_X_test = vAR_CLAB_X_test.astype('float32')\n",
        "\n",
        "# Normalize the pixel values\n",
        "vAR_CLAB_X_train /= 255\n",
        "vAR_CLAB_X_test /= 255\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "vAR_CLAB_y_train = to_categorical(vAR_CLAB_y_train, 10)\n",
        "vAR_CLAB_y_test = to_categorical(vAR_CLAB_y_test, 10)\n",
        "\n",
        "# Define the KNN model\n",
        "vAR_CLAB_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, input_shape=(784,), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "vAR_CLAB_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "vAR_CLAB_model.fit(vAR_CLAB_X_train, vAR_CLAB_y_train, epochs=5, batch_size=128)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "vAR_CLAB_test_loss, vAR_CLAB_test_acc = vAR_CLAB_model.evaluate(vAR_CLAB_X_test, vAR_CLAB_y_test)\n",
        "print('Test accuracy:', vAR_CLAB_test_acc)\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Explanation**\n",
        "\n",
        "The code is a script for training a neural network to perform image classification on the MNIST dataset. The script consists of the following steps:\n",
        "\n",
        "1. Import the necessary libraries:\n",
        "\n",
        "numpy is used for numerical computations\n",
        "tensorflow is used for building and training machine learning models\n",
        "mnist is a module within the tensorflow.keras.datasets package that contains the MNIST dataset\n",
        "to_categorical is a utility function from tensorflow.keras.utils that is used to convert class labels to one-hot encoded vectors"
      ],
      "metadata": {
        "id": "rxLw_4AkIi56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load the MNIST dataset:\n",
        "\n",
        "The mnist.load_data() function is used to load the MNIST dataset. It returns a tuple of two pairs of data and labels, one pair for the training data and labels and another pair for the test data and labels.\n",
        "The vAR_CLAB_X_train and vAR_CLAB_y_train variables store the training data and labels, respectively.\n",
        "The vAR_CLAB_X_test and vAR_CLAB_y_test variables store the test data and labels, respectively."
      ],
      "metadata": {
        "id": "94m3RuXBIitb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Pre-processing the data:\n",
        "\n",
        "The images are reshaped from a 3D array to a 2D array with each image represented as a 1D array.\n",
        "The data type of the arrays is converted from int to float32 to facilitate normalization.\n",
        "The pixel values are normalized by dividing by 255.\n",
        "The class labels are converted to one-hot encoded vectors using the to_categorical function."
      ],
      "metadata": {
        "id": "z9O6wFh1IigQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Building the model:\n",
        "\n",
        "A sequential model is created using the tf.keras.Sequential class.\n",
        "The model consists of a single dense layer with 10 neurons and a softmax activation function.\n",
        "The input shape of the layer is specified as (784,), which corresponds to the number of features in the flattened images."
      ],
      "metadata": {
        "id": "uhQWUcwdIiSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Compiling the model:\n",
        "\n",
        "The model is compiled using the compile method.\n",
        "The optimizer used is adam, the loss function is categorical_crossentropy, and the evaluation metric is accuracy."
      ],
      "metadata": {
        "id": "OCTHW2N3JF1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Training the model:\n",
        "\n",
        "The model is trained using the fit method with 5 epochs and a batch size of 128."
      ],
      "metadata": {
        "id": "jag7YaYKJFnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluating the model:\n",
        "\n",
        "The model is evaluated on the test data using the evaluate method.\n",
        "The test accuracy is computed and printed to the console."
      ],
      "metadata": {
        "id": "7QxMbqwJJFFo"
      }
    }
  ]
}