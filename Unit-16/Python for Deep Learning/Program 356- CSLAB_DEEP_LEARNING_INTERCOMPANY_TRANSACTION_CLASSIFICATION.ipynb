{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Ymm4KbpW+OpYudg8YHyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-16/Python%20for%20Deep%20Learning/Program%20356-%20CSLAB_DEEP_LEARNING_INTERCOMPANY_TRANSACTION_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15GrZ8cI-gSA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_DEEP_LEARNING_INTERCOMPANY_TRANSACTION_CLASSIFICATION\n",
        "  # Purpose \t:   A Program in Python for Intercompany Transaction Classification in Deep Learning\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   28/10/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program in Python for Intercompany Transaction Classification in Deep Learning\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda\n",
        "\n",
        "# coding=utf-8\n",
        "\n",
        "# Step 0 - Read Data from .INI File for Hardcoded Values\n",
        "\n",
        "#import sys\n",
        "#print('Arguments:', len(sys.argv))\n",
        "#vAR_Fetched_Data_INI_File_Path = sys.argv[1]\n",
        "#print(vAR_Fetched_Data_INI_File_Path)\n",
        "\n",
        "import configparser\n",
        "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
        "\n",
        "import os\n",
        "\n",
        "vAR_INI_File_Path = os.environ.get('PYTHON_TUTORIAL')\n",
        "\n",
        "import pandas as vAR_pd\n",
        "\n",
        "import configparser\n",
        "\n",
        "import pandas as vAR_pd\n",
        "\n",
        "vAR_Config = configparser.ConfigParser(allow_no_value=True)\n",
        "\n",
        "vAR_Config.read(vAR_INI_File_Path)\n",
        "\n",
        "vAR_CSLAB_INI_File = vAR_Config['Data File Path']['vAR_CSLAB_PROGRAM_356_INI_FILE']  \n",
        "\n",
        "vAR_Config.read(vAR_CSLAB_INI_File)\n",
        "\n",
        "vAR_Data = vAR_Config.sections()\n",
        "\n",
        "vAR_Config.sections()\n",
        "\n",
        "vAR_Fetched_Data_Source = vAR_Config['Data Source']['DATA_SOURCE1']\n",
        "#print(vAR_Fetched_Data_Source)\n",
        "\n",
        "vAR_Fetched_Data_Source_Connection_String = vAR_Config['Data Source Connection String']['SAP_CONNECTION_STRING']\n",
        "#print(vAR_Fetched_Data_Source_Connection_String)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Input_Data = vAR_Config['Data Source Path']['INPUT_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Input_Data)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Train_Data = vAR_Config['Data Source Path']['TRAIN_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Train_Data)\n",
        "\n",
        "vAR_Fetched_Data_Source_Path_Test_Data = vAR_Config['Data Source Path']['Test_DATA_PATH']\n",
        "#print(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features1 = vAR_Config['Train Features - Problem 1']['FEATURE1']\n",
        "#print(vAR_Fetched_Data_Train_Features1)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features2 = vAR_Config['Train Features - Problem 1']['FEATURE2']\n",
        "#print(vAR_Fetched_Data_Train_Features2)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features3 = vAR_Config['Train Features - Problem 1']['FEATURE3']\n",
        "#print(vAR_Fetched_Data_Train_Features3)\n",
        "\n",
        "vAR_Fetched_Data_Train_Features4 = vAR_Config['Train Features - Problem 1']['FEATURE4']\n",
        "#print(vAR_Fetched_Data_Train_Features4)\n",
        "\n",
        "vAR_Fetched_Data_Train_All_Features = vAR_Config['Train Features - Problem 1']['ALL_FEATURES_TRAIN']\n",
        "#print(vAR_Fetched_Data_Train_All_Features)\n",
        "\n",
        "vAR_Fetched_Data_Train_Label = vAR_Config['Train Label - Problem 1']['LABEL']\n",
        "#print(vAR_Fetched_Data_Train_Label)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features1 = vAR_Config['Test Features - Problem 1']['FEATURE1']\n",
        "#print(vAR_Fetched_Data_Test_Features1)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features2 = vAR_Config['Test Features - Problem 1']['FEATURE2']\n",
        "#print(vAR_Fetched_Data_Test_Features2)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features3 = vAR_Config['Test Features - Problem 1']['FEATURE3']\n",
        "#print(vAR_Fetched_Data_Test_Features3)\n",
        "\n",
        "vAR_Fetched_Data_Test_Features4 = vAR_Config['Test Features - Problem 1']['FEATURE4']\n",
        "#print(vAR_Fetched_Data_Test_Features4)\n",
        "\n",
        "vAR_Fetched_Data_Test_All_Features = vAR_Config['Test Features - Problem 1']['ALL_FEATURES_TEST']\n",
        "#print(vAR_Fetched_Data_Test_All_Features)\n",
        "\n",
        "vAR_Fetched_Data_Model_Path = vAR_Config['Model Ouput Path']['MODEL_OUTPUT_PATH']\n",
        "#print(vAR_Fetched_Data_Model_Path)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_1 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_2 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_File_Example_3 = vAR_Config['Model Fitting']['BEST_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Best_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_1 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_2 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Best_Fit_Image_Example_3 = vAR_Config['Model Fitting']['BEST_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Best_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_1 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_2 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_File_Example_3 = vAR_Config['Model Fitting']['UNDER_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Under_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_1 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_2 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Under_Fit_Image_Example_3 = vAR_Config['Model Fitting']['UNDER_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Under_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_1 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_2 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_File_Example_3 = vAR_Config['Model Fitting']['OVER_FIT_FILE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Over_Fit_File_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_1 = vAR_Config['Model Fitting']['OvER_FIT_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_2 = vAR_Config['Model Fitting']['OvER_FIT_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Over_Fit_Image_Example_3 = vAR_Config['Model Fitting']['OVER_FIT_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Over_Fit_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_1 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_1']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_1)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_2 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_2']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_2)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Image_Example_3 = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_IMAGE_EXAMPLE_3']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Image_Example_3)\n",
        "\n",
        "vAR_Fetched_Data_Before_Hyperparameter_Tuning_Image = vAR_Config['Model_Validation_Tuning']['BEFORE_HYPERPARAMETER_TUNING_IMAGE']\n",
        "#print(vAR_Fetched_Data_Before_Hyperparameter_Tuning_Image)\n",
        "\n",
        "vAR_Fetched_Data_After_Hyperparameter_Tuning_Image = vAR_Config['Model_Validation_Tuning']['AFTER_HYPERPARAMETER_TUNING_IMAGE']\n",
        "#print(vAR_Fetched_Data_After_Hyperparameter_Tuning_Image)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Best_Fit_Test = vAR_Config['Model Fitting']['BEST_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Best_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Under_Fit_Test = vAR_Config['Model Fitting']['UNDER_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Under_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Model_Fitting_Over_Fit_Test = vAR_Config['Model Fitting']['OVER_FIT_TEST_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Model_Fitting_Over_Fit_Test)\n",
        "\n",
        "vAR_Fetched_Data_Cross_Validation_Required = vAR_Config['Model_Validation_Tuning']['CROSS_VALIDATION_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Cross_Validation_Required)\n",
        "\n",
        "vAR_Fetched_Data_Hyperparameter_Tuning_Required = vAR_Config['Model_Validation_Tuning']['HYPERPARAMETERS_TUNING_REQUIRED']\n",
        "#print(vAR_Fetched_Data_Hyperparameter_Tuning_Required)\n",
        "\n",
        "# coding=utf-8\n",
        "\n",
        "# Step 1 - Import the Required Libraries\n",
        "\n",
        "#Our Model Implementation needs the Following Libraries:\n",
        "\n",
        "import pandas as vAR_pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 2 - Import Training Data\n",
        "\n",
        "#Next step after importing all libraries is getting the Training data imported. \n",
        "\n",
        "#We are importing the Clustering data stored in our local system with the use of Pandas library.\n",
        "\n",
        "vAR_df = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Input_Data)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 3 � Convert Categorical Data into Numerical Values using Label Encoder \n",
        "\n",
        "# Next Step of the Implementation is Convertion of Categorical Data into Numerical Values & Feature/Label Selection.\n",
        "\n",
        "vAR_le = LabelEncoder()\n",
        "vAR_Transaction_Type_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,7])\n",
        "vAR_Transaction_Type_Conversion_df = vAR_pd.DataFrame(vAR_Transaction_Type_Conversion,columns={'Transaction_Type_Converted'})\n",
        "vAR_Data_Category_Conversion = vAR_le.fit_transform(vAR_df.iloc[:,9])\n",
        "vAR_Data_Category_Conversion_df = vAR_pd.DataFrame(vAR_Data_Category_Conversion,columns={'Data_Category_Converted'})\n",
        "\n",
        "# Attached the Converted Numerical Data to the main dataframe\n",
        "\n",
        "vAR_df1 = vAR_df.merge(vAR_Transaction_Type_Conversion_df,left_index=True, right_index=True)\n",
        "vAR_df2 = vAR_df1.merge(vAR_Data_Category_Conversion_df,left_index=True, right_index=True)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 4 � Train the Model\n",
        "\n",
        "# Training the data means Making the model to Learn, understand & recognize the Pattern in the data.\n",
        "\n",
        "vAR_Features_train = vAR_pd.read_excel(vAR_Fetched_Data_Train_All_Features)\n",
        "vAR_Label_train = vAR_df.iloc[:,12]\n",
        "\n",
        "vAR_model = Sequential()\n",
        "\n",
        "vAR_model.add(Dense(4, input_shape=(4,), activation='relu',name='Input_Layer'))\n",
        "vAR_model.add(Dense(10, activation='relu',name='Hidden_Layer'))\n",
        "vAR_model.add(Dropout(0.5)) # Adding Dropout Prevents Overfitting\n",
        "vAR_model.add(Dense(1, activation='softmax', name='Output_Layer'))\n",
        "\n",
        "# Adam optimizer with learning rate of 0.005\n",
        "vAR_optimizer = Adam(lr=0.005)\n",
        "vAR_model.compile(vAR_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "vAR_model.fit(vAR_Features_train, vAR_Label_train, verbose=1, batch_size=5, epochs=200)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 5 � Review Learning Algorithm\n",
        "\n",
        "# We Review the Algorithm as to see how it has learned from the Features we Provided\n",
        "\n",
        "vAR_model.predict(vAR_Features_train)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 6 - Import Test Data\n",
        "\n",
        "# Importing the Test Data is to check how the data used on the Model Performs\n",
        "\n",
        "vAR_df3 = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "vAR_Transaction_Type_Conversion_test = vAR_le.fit_transform(vAR_df3.iloc[:,3])\n",
        "vAR_Transaction_Type_Conversion_test_df = vAR_pd.DataFrame(vAR_Transaction_Type_Conversion_test,columns={'Transaction_Type_Converted'})\n",
        "vAR_Data_Category_Conversion_test = vAR_le.fit_transform(vAR_df.iloc[:,4])\n",
        "vAR_Data_Category_Conversion_test_df = vAR_pd.DataFrame(vAR_Data_Category_Conversion_test,columns={'Data_Category_Converted'})\n",
        "vAR_df4 = vAR_df3.merge(vAR_Transaction_Type_Conversion_test_df,left_index=True, right_index=True)\n",
        "vAR_df5 = vAR_df4.merge(vAR_Data_Category_Conversion_test_df,left_index=True, right_index=True)\n",
        "\n",
        "vAR_Features_test = vAR_pd.read_excel(vAR_Fetched_Data_Test_All_Features)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 7 � Running Model on Test Data\n",
        "\n",
        "# Running the Model on Test Data is to use the imported test data to Prodict our Outcome\n",
        "\n",
        "vAR_Labels_Pred = vAR_model.predict(vAR_Features_test)\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 8 � Review Model Outcome\n",
        "\n",
        "# We check the Output of Model i.e the Prediction it has made on the test data\n",
        "\n",
        "vAR_Labels_Pred = vAR_pd.DataFrame(vAR_Labels_Pred,columns={'Predicted_Inter_Transaction_Type'})\n",
        "#vAR_Features_test = vAR_Features_test.sort()\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 9 - Write Model Outcome to File\n",
        "\n",
        "# Write the Model Output to an excel file for analysis.\n",
        "\n",
        "vAR_df6 = vAR_pd.read_excel(vAR_Fetched_Data_Source_Path_Test_Data)\n",
        "vAR_df7 = vAR_df6.merge(vAR_Labels_Pred,left_index=True, right_index=True)\n",
        "vAR_df8 = vAR_df7.to_excel(vAR_Fetched_Data_Model_Path, engine='xlsxwriter')\n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "# Step 10 - To open and view the file outcome\n",
        "\n",
        "#Open the Written File &amp; Check the Outcome as Shown. Execute to View the data\n",
        "\n",
        "vAR_df9 = vAR_pd.read_excel(vAR_Fetched_Data_Model_Path)\n",
        "vAR_df9     \n",
        "\n",
        "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
        "\n",
        "\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ]
    }
  ]
}