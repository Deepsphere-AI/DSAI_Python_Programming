{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy7Elot1zG8dOrKXExlen4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-13/Python%20for%20NLP/Program%20266-%20CSLAB_NLP_CHUNKING_NLTK_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVI8sIWXRVZU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_NLP_CHUNKING_NLTK_V1\n",
        "  # Purpose \t:   A Program in Python using NLP for Chunking\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   10/27/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program for Chunking using NLP in Python\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Anaconda\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import state_union\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "\n",
        "vAR_CSLvAR_CSLAB_AB_train_text = state_union.raw(\"2005-GWBush.txt\")\n",
        "vAR_CSLAB_sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
        "\n",
        "vAR_CSLAB_custom_sent_tokenizer = PunktSentenceTokenizer(vAR_CSLAB_train_text)\n",
        "\n",
        "vAR_CSLAB_tokenized = vAR_CSLAB_custom_sent_tokenizer.tokenize(vAR_CSLAB_sample_text)\n",
        "\n",
        "def vAR_CSLAB_process_content():\n",
        "    try:\n",
        "        for i in vAR_CSLAB_tokenized:\n",
        "            vAR_CSLAB_words = nltk.word_tokenize(i)\n",
        "            vAR_CSLAB_tagged = nltk.pos_tag(vAR_CSLAB_words)\n",
        "            vAR_CSLAB_chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
        "            vAR_CSLAB_chunkParser = nltk.RegexpParser(vAR_CSLAB_chunkGram)\n",
        "            vAR_CSLAB_chunked = vAR_CSLAB_chunkParser.parse(vAR_CSLAB_tagged)\n",
        "            vAR_CSLAB_chunked.draw()     \n",
        "\n",
        "    except Exception as vAR_CSLAB_e:\n",
        "        print(str(vAR_CSLAB_e))\n",
        "\n",
        "#vAR_CSLAB_process_content()\n",
        "    \n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ]
    }
  ]
}