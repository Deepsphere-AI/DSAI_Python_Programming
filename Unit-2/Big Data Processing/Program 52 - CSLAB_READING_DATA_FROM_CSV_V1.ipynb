{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-2/Big%20Data%20Processing/Program%2052%20-%20CSLAB_READING_DATA_FROM_CSV_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction to Follow:\n",
        "\n",
        "The Code given Below works on the google cloud environment with the Big Data environment (DataProc) and Hadoop file storage system Setup. It cannot be executed here in the google colaboratory notebook.  "
      ],
      "metadata": {
        "id": "8cd9RW99zcaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_READING_DATA_FROM_CSV_V1\n",
        "  # Purpose \t:   A Program in Python for Reading Data from a CSV File in Hdfs and GCS\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date and Time\t:   10/25/2022 \n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "\n",
        "## Program Description : Program for Reading Data from a CSV File in Hdfs and GCS\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Pyspark, Anaconda\n",
        "\n",
        "import pyspark \n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"hdfs_test\").getOrCreate()\n",
        "\n",
        "import pandas as vAR_pd\n",
        "\n",
        "vAR_df = spark.read.format('csv').load(\"hdfs:///user/dataproc/Patient Readmission.csv\",header=True,InferSchema=True)\n",
        "\n",
        "vAR_df\n",
        "\n",
        "vAR_df = spark.read.format('csv').load(\"gs://patientreadmission/Patient Readmission.csv\",header=True)\n",
        "\n",
        "vAR_df.head()\n",
        "\n",
        "vAR_df1 = vAR_df.toPandas()\n",
        "\n",
        "vAR_df1.head()\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ],
      "metadata": {
        "id": "19XmADLzzaaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}