{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepsphere-AI/DSAI_Python_Programming/blob/main/Unit-2/Big%20Data%20Processing/Program%2061%20-%20CSLAB_GRAPHING_MATPLOTLIB_USING_DEFAULTS_SETTING_LIMITS_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction to Follow:\n",
        "\n",
        "The Code given Below works on the google cloud environment with the Big Data environment (DataProc) and Hadoop file storage system Setup. It cannot be executed here in the google colaboratory notebook.  "
      ],
      "metadata": {
        "id": "r1NN5rYs6JOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# *********************************************************************************************************************\n",
        "  \n",
        "  # File Name \t:   CSLAB_GRAPHING_MATPLOTLIB_USING_DEFAULTS_SETTING_LIMITS_V1\n",
        "  # Purpose \t:   A Program in Python for Using & Setting Defaults in matplotlib\n",
        "  # Author\t:   Deepsphere.ai\n",
        "  # Reviewer \t:   Jothi Periasamy\n",
        "  # Date \t:   10/25/2022\n",
        "  # Version\t:   1.0\t\n",
        "  \n",
        "# ***********************************************************************************************************************\n",
        "   \n",
        "## Program Description : Program Using & Defaults in matplotlib in Python\n",
        "\n",
        "## Python Development Environment & Runtime - Python, Pyspark, Anaconda\n",
        "\n",
        "import pyspark \n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"hdfs_test\").getOrCreate()\n",
        "\n",
        "import matplotlib.pyplot as vAR_plt\n",
        "\n",
        "vAR_df = spark.read.format('csv').load(\"gs://patientreadmission/Patient Readmission.csv\",header=True)\n",
        "\n",
        "vAR_df1 = vAR_df.toPandas()\n",
        "\n",
        "vAR_fig, vAR_ax = vAR_plt.subplots()\n",
        "\n",
        "vAR_ax.plot(vAR_df1['patient_nbr'], vAR_df1['Weight(KG)'],color=\"blue\", linewidth=2, linestyle=\"--\")\n",
        "\n",
        "vAR_ax.set_ylim(0,103)\n",
        "\n",
        "#vAR_ax.set_xlim(0,10)\n",
        "\n",
        "vAR_plt.xlabel('Patient_number')\n",
        "\n",
        "vAR_plt.ylabel('Weight in KG')\n",
        "\n",
        "vAR_plt.show()\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "#   Disclaimer.\n",
        "\n",
        "# We are providing this code block strictly for learning and researching, this is not a production\n",
        "# ready code. We have no liability on this particular code under any circumstances; users should use\n",
        "# this code on their own risk. All software, hardware and othr products that are referenced in these \n",
        "# materials belong to the respective vendor who developed or who owns this product.\n",
        "\n",
        "# ****************************************************************************************************************************\n",
        "  "
      ],
      "metadata": {
        "id": "t5qgtiPQ6KCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}